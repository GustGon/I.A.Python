{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Transferencia_estilo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GustGon/I.A.Python/blob/master/%5Cneural-network%5Cnn-convulational%5CTransferencia_estilo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgsLzFX8HC9x",
        "colab_type": "text"
      },
      "source": [
        "# Trabalho #6 - Transferência de Estilo\n",
        "\n",
        "Nesse trabalho você vai utilizar uma RNA pré-treinada para alterar estilo de uma imagem. A rede pré-treinada que será utilizada é a VGG19 que está disponível no Keras.\n",
        "\n",
        "Nesse trabalho você vai fazer:\n",
        "\n",
        "- Implementar o método de transferência de estilo;\n",
        "- Gerar imagens com novos estilos de arte;\n",
        "- Os algoritmos estudados até o momento minimizam uma função de custo para obter os parâmetros de uma RNA. Na transferência de estilo uma função de custo é minimizada para obter os valores dos pixels de uma imagem.\n",
        "\n",
        "O método de transferência de estilo usado nesse trabalho foi criado por Gatys et al. (2015) (https://arxiv.org/abs/1508.06576).\n",
        "\n",
        "O algortimo implementado nesse notebook foi desenvolvido por: https://github.com/tensorflow/models/blob/master/research/nst_blogpost/4_Neural_Style_Transfer_with_Eager_Execution.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O4sZel4HC9y",
        "colab_type": "text"
      },
      "source": [
        "## Coloque os nomes e RAs dos alunos que fizeram esse trabalho\n",
        "\n",
        "Nome e número dos alunos da equipe:\n",
        "\n",
        "Aluno 1: Gustavo da Silva Gonçalves   RA: 19.83842-5\n",
        "\n",
        "Aluno 2: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Td9j1MMHC9y",
        "colab_type": "text"
      },
      "source": [
        "## 1 - Definição do problema\n",
        "\n",
        "A transferência de estilo realizada por uma rede neural (NST) é uma das técnicas mais interessantes de \"deep-learning\". Como visto em aula a NST mescla duas imagens, a imagem de \"conteúdo\" (**C**) e a imagem de \"estilo\" (**S**), para criar uma nova imagem \"gerada\" (**G**). A imagem gerada **G** combina o \"conteúdo\" da imagem **C** com o \"estilo\" da imagem **S**.\n",
        "\n",
        "Neste trabalho você irá gerar uma imagem do museu do Louvre em Paris (imagem de conteúdo **C**) com o estilo de uma pintura de Claude Monet, líder do movimento impressionista (imagem de estilo **S**).\n",
        "\n",
        "A transferência de estilo neural (NST) usa uma rede convolucional previamente treinada. Como já visto em aula, a idéia de usar uma rede pré-treinada em uma tarefa diferente e aplicá-la a uma nova tarefa é chamada de transferência de aprendizado.\n",
        "\n",
        "Seguindo o trabalho original do NST (https://arxiv.org/abs/1508.06576) usaremos a rede VGG19, que é uma versão de 19 camadas da rede VGG. A VGG19 foi treinada no banco de dados ImageNet que possui milhões de imagens e, portanto, é capaz de reconhecer uma grande variedade de características de baixo nível (presentes nas camadas iniciais da RNA) e de alto nível (presentes nas camadas mais profundas)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giWQpT5ZHC9z",
        "colab_type": "text"
      },
      "source": [
        "## 2 - Preparação e inicialização do ambiente  e das imagens\n",
        "\n",
        "### Importação das bibliotecas\n",
        "\n",
        "Execute a célula abaixo para importar as bibliotecas necessárias para esse trabalho."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAZ2EPafHC90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['figure.figsize'] = (10,10)\n",
        "mpl.rcParams['axes.grid'] = False\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import time\n",
        "import functools\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.eager as tfe\n",
        "from tensorflow.python.keras.preprocessing import image as kp_image\n",
        "from tensorflow.python.keras import models \n",
        "from tensorflow.python.keras import losses\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Blj4LaFNHC92",
        "colab_type": "text"
      },
      "source": [
        "### Exercício #1: Inicialização da sessão do TensorFlow\n",
        "\n",
        "Nesse trabalho usaremos uma sessão \"eager\" do TensorFlow, que permite visualizar na hora os resultados obtidos. Assim, modificque a célula abaixo para iniciar uma sessão \"eager\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koPmVvPNHC92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARA VOCÊ FAZER: iniciar uma sessão eager do TensorFlow\n",
        "\n",
        "### COMECE AQUI ### (≈ 1 linha) \n",
        "#\n",
        "### TERMINE AQUI ###\n",
        "\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-0-9L_1HC94",
        "colab_type": "text"
      },
      "source": [
        "**Saída esperada:**\n",
        "\n",
        "Eager execution: True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1_uvPLXHC95",
        "colab_type": "text"
      },
      "source": [
        "### Visualização das imagens de entrada\n",
        "\n",
        "Execute as células abaixo para definir e visualizar as imagens que serão mescladas. Essas são as imagens de conteúdo e de estilo. O que queremos é criar uma nova imagem com o conteúdo da imagem de \"conteúdo\" e com o estilo da imagem de \"estilo\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcDpKkd-HC95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definição de variáveis globais e visualização da simagens\n",
        "\n",
        "content_path = 'images/louvre.jpg' \n",
        "style_path = 'images/monet_800600.jpg'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeUBeLALHC97",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Função para ler imagem e transformar em um array do TensorFlow\n",
        "\n",
        "def load_img(path_to_img):\n",
        "    max_dim = 512\n",
        "    img = Image.open(path_to_img)\n",
        "    long = max(img.size)\n",
        "    scale = max_dim/long\n",
        "    img = img.resize((round(img.size[0]*scale), round(img.size[1]*scale)), Image.ANTIALIAS)\n",
        "    img = kp_image.img_to_array(img)\n",
        "  \n",
        "    # We need to broadcast the image array such that it has a batch dimension \n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om4rwxD7HC99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Função para mostrar imagem\n",
        "\n",
        "def imshow(img, title=None):\n",
        "    # Remove the batch dimension\n",
        "    out = np.squeeze(img, axis=0)\n",
        "    # Normalize for display \n",
        "    out = out.astype('uint8')\n",
        "    plt.imshow(out)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "        plt.imshow(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfH4y8gNHC9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mostra as imagens de conteúdo e de estilo\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "\n",
        "content = load_img(content_path).astype('uint8')\n",
        "style = load_img(style_path).astype('uint8')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "imshow(content, 'Content Image')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "imshow(style, 'Style Image')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZrgOqkeHC-B",
        "colab_type": "text"
      },
      "source": [
        "## 2 - RNA convolucional base\n",
        "\n",
        "Nesse trabalho você irá usar uma RNA convolucional já treinada para processar as imagens e extrair as ativações das camadas para formar as funções de custo de conteúdo e de estilo. A RNA que será usada como base é a VGG19 (Simonyan & Zisserman, Very deep convolutional networks for large-scale image recognition, 2015). \n",
        "\n",
        "Como já visto as RNAs VGG16 e VGG19 foram desenvolvidas para classificação de múltiplas classes com 1.000 classes. Ela é utilizadas para reconhecimento de objetos em imagens. A arquitetura das VGGs é muito simples, sendo composta pela repetição de camadas convolucionais formando blocos. Cada bloco é composto por duas ou três camadas convolucionais, com filtros 3x3, stride = 1 e “same convolution”, seguida por uma camada de max-pooling, com janela 2x2 e stride = 2. A VGG19 mantém praticamente o mesmo padrão em todos os blocos dobrando o número de filtros a cada bloco. Apesar da VGG19 possuir muitos parâmetros, cerca de 143 milhões, ela é muito simples.\n",
        "\n",
        "### Exercício #2: Importação da RNA VGG19\n",
        "\n",
        "O TensorFlow/keras possui na sua base de dados a RNA VGG19 treinada com o banco de imagens imagenet. Na célula abaixo carregue a VGG19 usando o comando do TensorFlow `keras.applications.vgg19.VGG19`. Não se esqueça de excluir as camadas densas da VGG19 ao importá-la e de incluir os \"weigths\" desejados. Nesse caso não é preciso informar a dimensão da imagem de entrada nessa etapa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Th7Vm5gHC-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARA VOCÊ FAZER: Carregar e salvar a VGG19 na rna-base\n",
        "\n",
        "### COMECE AQUI ### (≈ 1 linha) \n",
        "#rna = \n",
        "### TERMINE AQUI ###\n",
        "\n",
        "rna.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZJ7i1qXHC-D",
        "colab_type": "text"
      },
      "source": [
        "**Saída esperada:** Para conferência incluimos somente o número de parâmetros.\n",
        "\n",
        "     Total params: 20,024,384\n",
        "     Trainable params: 20,024,384\n",
        "     Non-trainable params: 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNQjNm2vHC-E",
        "colab_type": "text"
      },
      "source": [
        "### Preparação dos dados\n",
        "\n",
        "Precisamos criar funções que permitem carregar e pré-processar imagens para serem utilizadas pela rede VGG19. Devemos realizar o mesmo pré-processamento utilizado nas imagens processadas pela rede VGG19. A rede VGG19 é treinada com imagens onde cada canal RGB é normalizado usando as seguintes médias = [103,939, 116,779, 123,68].\n",
        "\n",
        "Execute a célula abaixo para definir a função que realiza a normalização das imagens de acordo com o esperado pela VGG19. A função `tf.keras.applications.vgg19.preprocess_input()` já está pronta para fazer essa normalização."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfcv1J6wHC-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import vgg19\n",
        "\n",
        "def load_and_process_img(path_to_img):\n",
        "    img = load_img(path_to_img)\n",
        "    img = tf.keras.applications.vgg19.preprocess_input(img)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL8fGN2_HC-G",
        "colab_type": "text"
      },
      "source": [
        "Para visualizar os resultados da nossa transferência de estilo, temos que executar a etapa inversa de pré-processamento. Além disso, como a imagem gerada pode ter valores entre −∞  e  ∞, precisamos incluir um limite para manter os valores dentro do intervalo de 0 a 255. Execute a célula abaixo para definir a função deprocess_img que realiza esse cálculo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHq6PHYLHC-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def deprocess_img(processed_img):\n",
        "    x = processed_img.copy()\n",
        "    if len(x.shape) == 4:\n",
        "        x = np.squeeze(x, 0)\n",
        "    \n",
        "    assert len(x.shape) == 3, (\"Input to deprocess image must be an image of \"\n",
        "                               \"dimension [1, height, width, channel] or [height, width, channel]\")\n",
        "    if len(x.shape) != 3:\n",
        "        raise ValueError(\"Invalid input to deprocessing image\")\n",
        "  \n",
        "    # perform the inverse of the preprocessiing step\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    x = x[:, :, ::-1]\n",
        "\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-0gm1XrHC-I",
        "colab_type": "text"
      },
      "source": [
        "## 3 - Definição das representações de conteúdo e estilo\n",
        "\n",
        "Como visto em aula, para obter as representações de conteúdo e estilo de uma imagem, devemos escolher algumas camadas intermediárias da rede convolucional. Na medida em que aprofundamos na rede convolucional, as camadas intermediárias representam características cada vez mais elaboradas. As saídas dessas camadas intermediárias são necessárias para definir a representação do conteúdo e do estilo das imagens.\n",
        "\n",
        "As saídas das camadas intermediárias de uma rede convulocional, que foi pré-treinada para uma tarefa de classificação, permite definir representações de estilo e conteúdo. De forma geral, isso pode ser explicado pelo fato de que para uma rede executar a classificação de uma imagem, ela deve ser capaz de \"entender\" a imagem. Isso envolve processar os pixels da imagem e construir uma representação interna que permite uma compreensão complexa das caracteríticas presentes na imagem. As redes neurais convolucionais são capazes de capturar as invariâncias e as características que definem classes (por exemplo, gatos versus cães) e que não dependem de ruídos de fundo e outras sutilezas. Assim, qualquer camada convolucional de uma RNA convolucional serve como um extrator de caracteríticas, portanto, ao acessar as saídas de camadas intermediárias, podemos descrever o conteúdo e o estilo da imagem processada.\n",
        "\n",
        "### Exercício #3: Definição das camadas de conteúdo e de estilo\n",
        "\n",
        "Modifique a célula abaixo para incluir as camadas da VGG19 em duas listas que serão usadas para definir conteúdo e estilo:\n",
        "\n",
        "- Camada de conteúdo: `block5_conv2`\n",
        "- Camadas de estilo: `block1_conv1`, `block2_conv1`, `block3_conv1`, `block4_conv1` e `block5_conv1`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7TGJqzUHC-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARA VOCÊ FAZER: Camadas de conteúdo e de estilo\n",
        "\n",
        "# Camada de conteúdo\n",
        "### COMECE AQUI ### (≈ 1 linha)\n",
        "#content_layers = \n",
        "### TERMINE AQUI ###\n",
        "\n",
        "# Camdas de estilo. Inclua uma lista com os nomes das camadas\n",
        "### COMECE AQUI ### (≈ 1 linha)\n",
        "#style_layers = \n",
        "### TERMINE AQUI ###\n",
        "\n",
        "num_content_layers = len(content_layers)\n",
        "num_style_layers = len(style_layers)\n",
        "\n",
        "print('Camadas de conteúdo:', content_layers)\n",
        "print('Camadas de estilo:', style_layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40jyvMRbHC-K",
        "colab_type": "text"
      },
      "source": [
        "**Saída esperada:**\n",
        "    \n",
        "    Camadas de conteúdo: ['block5_conv2']\n",
        "    Camadas de estilo: ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqmcE6JRHC-L",
        "colab_type": "text"
      },
      "source": [
        "## 4 - Construção do modelo\n",
        "\n",
        "Para construir o modelo usado para a transferência de estilo devemos carregar a VGG19, fornecer o tensor de entrada e definir os tensores de saída. Isso permite extrair os mapas de caracteríticas de conteúdo e de estilo e obter a imagem gerada. Usamos a VGG19, conforme sugerido no trabalho original de transferência de estilo. Uma das vantagens da VGG19 é que é uma RNA  relativamente simples (comparada as redes ResNet, Inception etc.), assim, os mapas de características funcionam melhor para a transferência de estilos.\n",
        "\n",
        "Para acessar as camadas intermediárias correspondentes aos mapas de caracterísitcas de estilo e conteúdo, obtemos as saídas correspondentes dessas camadas e definimos nosso modelo com as ativações das saídas desejadas. Com a classe API Funcional do Keras, a definição de um modelo envolve simplesmente a definição das entradas e saídas, ou seja: \n",
        "`model = Modelo (entradas, saídas)`. \n",
        "\n",
        "Execute a célula abaixo para criar o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV3Z7BoeHC-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    \"\"\" Creates our model with access to intermediate layers. \n",
        "  \n",
        "    This function will load the VGG19 model and access the intermediate layers. \n",
        "    These layers will then be used to create a new model that will take input image\n",
        "    and return the outputs from these intermediate layers from the VGG model. \n",
        "  \n",
        "    Returns:\n",
        "        returns a keras model that takes image inputs and outputs the style and \n",
        "        content intermediate layers. \n",
        "    \"\"\"\n",
        "    \n",
        "    # Load our model. We load pretrained VGG, trained on imagenet data\n",
        "    vgg = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet')\n",
        "    vgg.trainable = False\n",
        "  \n",
        "    # Get output layers corresponding to style and content layers \n",
        "    style_outputs = [vgg.get_layer(name).output for name in style_layers]\n",
        "    content_outputs = [vgg.get_layer(name).output for name in content_layers]\n",
        "    model_outputs = style_outputs + content_outputs\n",
        "  \n",
        "    # Build model \n",
        "    return models.Model(vgg.input, model_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwZC1U4YHC-N",
        "colab_type": "text"
      },
      "source": [
        "## 5 - Funções de custo de conteúdo e estilo\n",
        "\n",
        "\n",
        "### 5.1 Função de custo de conteúdo\n",
        "\n",
        "Como visto em aula, a função de custo de conteúdo é realmente bastante simples. Passamos como entradas para a RNA convolucional a imagem de conteúdo desejada e a imagem gerada (uma de cada vez). Isso retorna as saídas da camada intermediária definida como camada de conteúdo para ambas as imagens. Então, simplesmente tomamos a distância euclidiana entre as duas representações intermediárias dessas imagens.\n",
        "\n",
        "Mais formalmente, a função de custo de conteúdo descreve a distância do conteúdo da imagem gerada **G**, com o conteúdo da imagem de conteúdo **C**. Seja $C_{nn}$ a RNA convolucional VGG19 pré-treinada e seja **X** uma imagem qualquer, então $C_{nn}(X)$ é a rede alimentada pela imagem **X**. Seja $a^{[l]C} \\in C_{nn}(C)$ e $a^{[l]G} \\in C_{nn}(G)$ as saídas da camada intermediária $l$ da RNA com entradas **C** e **G** respectivamente. A distância entre $a^{[l]C}$ e $a^{[l]G}$, ou seja, o custo de conteúdo, é formalmente definida como sendo: \n",
        "\n",
        "$$J_C(C, G) = \\frac {1} {2} \\sum_{i, j} (a^{[l]C} - a^{[l]G})^2$$\n",
        "\n",
        "\n",
        "### Exercício #4: Função de custo de conteúdo\n",
        "\n",
        "Implemente na célula abaixo uma função para calcular o custo de conteúdo, que é definido como sendo o erro entre as saídas da `content_layer` das imagens de conteúdo e gerada, conforme definido na equação acima. Use as funções `reduce_mean` e `square` do TensorFlow [Dica 1](https://www.tensorflow.org/api_docs/python/tf/reduce_mean) e [Dica 2](https://www.tensorflow.org/api_docs/python/tf/square).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QJHUdFUHC-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARA VOCÊ FAZER: Função de custo de conteúdo\n",
        "\n",
        "def get_content_loss(base_content, target):\n",
        "    ### COMECE AQUI ### (≈ 1 linha)\n",
        "    #JC = \n",
        "    ### TERMINE AQUI ###\n",
        "    return JC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4U-2pcFHC-P",
        "colab_type": "text"
      },
      "source": [
        "Execute a célula abaixo para verificar se a sua função de custo conteúdo foi implmentada corretamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNvA7yuuHC-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(3)\n",
        "aC = np.random.random((3,3))\n",
        "aG = np.random.random((3,3))\n",
        "JC = get_content_loss(aC, aG)\n",
        "print('Custo de conteúdo=', JC)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXBYPVA2HC-R",
        "colab_type": "text"
      },
      "source": [
        "**Saída esperada:**\n",
        "\n",
        "Custo de conteúdo= tf.Tensor(0.08068334147758457, shape=(), dtype=float64)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2z4xcS1HC-S",
        "colab_type": "text"
      },
      "source": [
        "### 5.2 Matriz de Gram\n",
        "\n",
        "Execute a célula abaixo para definir o cálculo da matriz de Gram. A fórmula para calcular a matriz de Gram da matriz **A** é dada por:\n",
        "\n",
        "$$M = AA^T$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYqTjFGmHC-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gram_matrix(input_tensor):\n",
        "    # We make the image channels first \n",
        "    channels = int(input_tensor.shape[-1])\n",
        "    A = tf.reshape(input_tensor, [-1, channels])\n",
        "    n = tf.shape(A)[0]\n",
        "    gram = tf.matmul(A, A, transpose_a=True)\n",
        "    return gram / tf.cast(n, tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_rMUZjLHC-U",
        "colab_type": "text"
      },
      "source": [
        "### 5.3 Função de custo de estilo\n",
        "\n",
        "O cálculo da função de custo de estilo é um pouco mais complexo, mas segue o mesmo princípio, desta vez alimentando nossa rede com as imagenes de conteúdo **C** e de estilo **S**. No entanto, em vez de comparar as saídas das camadas intermediárias comparamos as matrizes Gram das duas saídas.\n",
        "\n",
        "Matematicamente, descrevemos a perda de estilo entre a imagem de conteúdo, **C**, e a imagem do estilo, **S**, como sendo a distância entre a representação do estilo (matrizes de Gram) dessas duas imagens. \n",
        "\n",
        "Descrevemos a representação do estilo de uma imagem como sendo a correlação entre as saídas de diferentes filtros fornecida pela matriz de Gram da camada $l$, **M**$^{[l]}$, onde cada elemento dessa matriz, $m^{[l]}_{i,j}$, é o produto escalar entre as saídas dos filtros $i$ e $j$ da camada $l$.\n",
        "\n",
        "A contribuição de cada camada no custo de estilo é descrita por:\n",
        "\n",
        "$$J^{[l]}_S(S,G) = \\frac {1} {2n^{[l]}_H n^{[l]}_W n^{[l]}_C} \\sum_ {i, j} (m^{[l]S}_{ij} - m^{[l]G}_{ij})^2 \\tag{1}$$\n",
        "\n",
        "onde $m^{[l]S}_{ij}$ e $m^{[l]G}_{ij}$ são respectivamente as representações de estilo da camada $l$ de **S** e **G**, $n^{[l]}_C$ é o número de filtros (canais) da camada $l$, cada um com dimensão  $n^{[l]}_H$ por $n^{[l]}_W$. \n",
        "\n",
        "Assim, a perda total de estilo é obtida somando as perdas em cada uma das camadas usadas para descrever o estilo, ou seja:\n",
        "\n",
        "$$J_S(S,G) = \\sum_{l \\in L} \\lambda^{[l]} J^{[l]}_S(S,G) \\tag{2}$$\n",
        "\n",
        "Observe que ponderamos a contribuição da perda de cada camada pelo fator $\\lambda^{[l]}$. No nosso caso, iremos ponderar cada camada igualmente por $\\lambda^{[l]} = \\frac{1}{|L|}$.\n",
        "\n",
        "### Exercício #5: Função de custo de estilo da camada $l$\n",
        "\n",
        "Implemente na célula abaixo uma função para calcular a função de custo de estilo das imagens de estilo e gerada da camada $l$, conforme definido na equação (1) acima. Use as funções `reduce_mean` e `square` do TensorFlow e a função `gram_matrix` definida anteriormente.\n",
        "\n",
        "Observe que como a imagem de estilo não muda durante o cálculo, então, a matriz de Gram dessa imagem não precisa ser calculada a todo momento, bastando calculá-la no início do processo. Dessa forma, a função custo de estilo recebe as saídas das camadas definidas para calcular o estilo da imagem gerada (`base_style`) e a matriz de Gram da imagem de estilo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7mnE7zSHC-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARA VOCÊ FAZER: Função de custo de estilo de uma camada\n",
        "\n",
        "def get_style_loss(base_style, gram_target):\n",
        "    \"\"\"Expects two images of dimension h, w, c\"\"\"\n",
        "    # height, width, num filters of each layer\n",
        "    # base_style = saídas das camadas de \"estilo\" referentes à imagem gerada\n",
        "    # gram_target = matriz de Gram calculada para cada camada de \"estilo\" referente á imagem de estilo\n",
        "  \n",
        "    height, width, channels = base_style.get_shape().as_list()\n",
        "    \n",
        "    ### COMECE AQUI ### (≈ 2 linhas)\n",
        "    #gram_style = \n",
        "    #JS = \n",
        "    ### TERMINE AQUI ####\n",
        "    \n",
        "    return JS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb_F5yB1HC-Y",
        "colab_type": "text"
      },
      "source": [
        "Execute a célula abaixo ara verificar se a sua função de custo de estilo foi implementada corretamente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4VBbF9-HC-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(3)\n",
        "MC = tf.Variable(np.random.random((3,3,3)), dtype=tf.float32)\n",
        "MG = np.random.random((3,3,3))\n",
        "JS = get_style_loss(MC, MG)\n",
        "print(JS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5An5kVopHC-a",
        "colab_type": "text"
      },
      "source": [
        "**Saída esperada:**\n",
        "\n",
        "tf.Tensor(0.0023269579, shape=(), dtype=float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8K-ytXOHC-b",
        "colab_type": "text"
      },
      "source": [
        "### Exercício #6: Cálculo das características das imagens de conteúdo e de estilo\n",
        "\n",
        "Precisamos calcular as características das imagens de conteúdo e de estilo para serem usadas como representações de conteúdo e estilo do nosso modelo. Para isso, vamos definir a função `get_feature_representations` que calcula essas características. Na célula abaixo calcule as características das imagens de conteúdo e de estilo usando a VGG19 recebida no objeto `model` e a \"path\" para as imagens de conteúdo e de estilo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSjB0nkDHC-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARA VOCÊ FAZER: Cálculo das representações de conteúdo e de estilo\n",
        "\n",
        "def get_feature_representations(model, content_path, style_path):\n",
        "    \"\"\"Function to compute our content and style feature representations.\n",
        "\n",
        "    This function will simply load and preprocess both the content and style \n",
        "    images from their path. Then it will feed them through the network to obtain\n",
        "    the outputs of the intermediate layers. \n",
        "  \n",
        "    Arguments:\n",
        "        model: The model that we are using.\n",
        "        content_path: The path to the content image.\n",
        "        style_path: The path to the style image\n",
        "    \n",
        "    Returns:\n",
        "        returns the style features and the content features. \n",
        "    \"\"\"\n",
        "  \n",
        "    # Load our images in\n",
        "    # Usando a função load_and_process_img carregue as imagens de conteùdo e de estilo\n",
        "    ### COMECE AQUI ### (≈ 2 linhas)\n",
        "    #content_image = \n",
        "    #style_image = \n",
        "    ### TERMINE AQUI ###\n",
        "  \n",
        "    # Usando a RNA VGG19 recebida no objeto \"model\", calcule as caracteríticas das imagens de conteúdo e de estilo\n",
        "    ### COMECE AQUI ### (≈ 2 linhas)\n",
        "    #style_outputs = \n",
        "    #content_outputs = \n",
        "    ### TERMINE AQUI ###\n",
        "  \n",
        "    # Get the style and content feature representations from our model  \n",
        "    style_features = [style_layer[0] for style_layer in style_outputs[:num_style_layers]]\n",
        "    content_features = [content_layer[0] for content_layer in content_outputs[num_style_layers:]]\n",
        "      \n",
        "    return style_features, content_features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxI0yFqcHC-d",
        "colab_type": "text"
      },
      "source": [
        "### 5.4 Função de custo total\n",
        "\n",
        "A função `compute_loss` implementada na célula abaixo calcula a função de custo total para realizar a transferência de estilo. Portanto, execute a célula abaixo para definir essa função."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HprfIe1OHC-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_loss(model, loss_weights, init_image, gram_style_features, content_features):\n",
        "    \"\"\"This function will compute the loss total loss.\n",
        "  \n",
        "    Arguments:\n",
        "        model: The model that will give us access to the intermediate layers\n",
        "        loss_weights: The weights of each contribution of each loss function. \n",
        "             (style weight and content weight)\n",
        "        init_image: Our initial base image. This image is what we are updating with \n",
        "            our optimization process. We apply the gradients wrt the loss we are \n",
        "            calculating to this image.\n",
        "        gram_style_features: Precomputed gram matrices corresponding to the \n",
        "            defined style layers of interest.\n",
        "        content_features: Precomputed outputs from defined content layers of \n",
        "            interest.\n",
        "      \n",
        "    Returns:\n",
        "        returns the total loss, style loss, content loss, and total variational loss\n",
        "    \"\"\"\n",
        "  \n",
        "    style_weight, content_weight = loss_weights\n",
        "  \n",
        "    # Feed our init image through our model. This will give us the content and \n",
        "    # style representations at our desired layers. Since we're using eager\n",
        "    # our model is calpable just like any other function!\n",
        "    model_outputs = model(init_image)\n",
        "  \n",
        "    style_output_features = model_outputs[:num_style_layers]\n",
        "    content_output_features = model_outputs[num_style_layers:]\n",
        "  \n",
        "    style_score = 0\n",
        "    content_score = 0\n",
        "\n",
        "    # Accumulate style losses from all layers\n",
        "    # Here, we equally weight each contribution of each loss layer\n",
        "    weight_per_style_layer = 1.0 / float(num_style_layers)\n",
        "    for target_style, comb_style in zip(gram_style_features, style_output_features):\n",
        "        style_score += weight_per_style_layer * get_style_loss(comb_style[0], target_style)\n",
        "    \n",
        "    # Accumulate content losses from all layers \n",
        "    weight_per_content_layer = 1.0 / float(num_content_layers)\n",
        "    for target_content, comb_content in zip(content_features, content_output_features):\n",
        "        content_score += weight_per_content_layer* get_content_loss(comb_content[0], target_content)\n",
        "  \n",
        "    style_score *= style_weight\n",
        "    content_score *= content_weight\n",
        "\n",
        "    # Get total loss\n",
        "    loss = style_score + content_score \n",
        "  \n",
        "    return loss, style_score, content_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTn2Soh3HC-g",
        "colab_type": "text"
      },
      "source": [
        "## 6 - Transferência de estilo entre as imagens\n",
        "\n",
        "Nesse trabalho usaremos o otimizador Adam para minimizar a função de custo total. Atualizamos iterativamente a imagem de saída (imagem gerada) para minimizar a função de custo total. Na transferência de estilo não atualizamos os pesos associados à nossa rede como de costume, mas treinamos a imagem de entrada para minimizar a perda, conforme a equação abaixo.\n",
        "\n",
        "$$G = G - \\frac{\\partial J(G)}{\\partial G}$$\n",
        "\n",
        "\n",
        "Para fazer esse cálculo precisamos calcular além da função de custo total o seu gradiente em relação aos pixels da imagem gerada.\n",
        "\n",
        "\n",
        "### 6.1 Cálculo do gradiente\n",
        "\n",
        "Execute a célula abaixo para definir a função `compute_grads` que calcula o gradiente da função de custo total em relação aos pixels da imagem gerada. Essa função utliza a função do TensorFlow `tf.GradientTape()`(https://www.tensorflow.org/api_docs/python/tf/GradientTape) para calcular o gradiente $\\frac{\\partial J(G)}{\\partial G}$ e a função `compute_loss` (definda acima) para calcular o custo total $J(G)$. \n",
        "\n",
        "A função `tf.GradientTape()` calcula automaticamente as derivadas usando as operações definidas para calcular a função de custo total, facilitando a implementação do processo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lk-WviYHC-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_grads(cfg):\n",
        "    with tf.GradientTape() as G: \n",
        "        all_loss = compute_loss(**cfg)\n",
        "  \n",
        "    # Compute gradients wrt input image\n",
        "    total_loss = all_loss[0]\n",
        "  \n",
        "    return G.gradient(total_loss, cfg['init_image']), all_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO8WbDQ1HC-i",
        "colab_type": "text"
      },
      "source": [
        "### 6.2 Juntando todas as funções\n",
        "\n",
        "Execute a célula abaixo para definir a função que implementa o método iterativo da transferência de estilo chamando as funções definidas anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOP-pU5KHC-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython.display\n",
        "\n",
        "def run_style_transfer(content_path, style_path, num_iterations=1000, content_weight=1e3, style_weight=1e3): \n",
        "    # We don't need to (or want to) train any layers of our model, so we set their trainable to false. \n",
        "    model = get_model() \n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "        \n",
        "    # Get the style and content feature representations (from our specified intermediate layers) \n",
        "    style_features, content_features = get_feature_representations(model, content_path, style_path)\n",
        "    gram_style_features = [gram_matrix(style_feature) for style_feature in style_features]\n",
        "  \n",
        "    # Set initial image as the content image\n",
        "    init_image = load_and_process_img(content_path)\n",
        "    init_image = tfe.Variable(init_image, dtype=tf.float32)\n",
        "  \n",
        "    # Create our optimizer\n",
        "    opt = tf.train.AdamOptimizer(learning_rate=5, beta1=0.99, epsilon=1e-1)\n",
        "    \n",
        "    # For displaying intermediate images \n",
        "    iter_count = 1\n",
        "  \n",
        "    # Store our best result\n",
        "    best_loss, best_img = float('inf'), None\n",
        "  \n",
        "    # Create a nice config \n",
        "    loss_weights = (style_weight, content_weight)\n",
        "    cfg = {'model': model,'loss_weights': loss_weights,'init_image': init_image,'gram_style_features': gram_style_features,'content_features': content_features}    \n",
        "\n",
        "    # For displaying\n",
        "    num_rows = 2\n",
        "    num_cols = 5\n",
        "    display_interval = num_iterations/(num_rows*num_cols)\n",
        "    start_time = time.time()\n",
        "    global_start = time.time()\n",
        "  \n",
        "    norm_means = np.array([103.939, 116.779, 123.68])\n",
        "    min_vals = -norm_means\n",
        "    max_vals = 255 - norm_means   \n",
        "  \n",
        "    imgs = []\n",
        "    history = np.zeros(num_iterations)\n",
        "    \n",
        "    for i in range(num_iterations):\n",
        "        grads, all_loss = compute_grads(cfg)\n",
        "        loss, style_score, content_score = all_loss\n",
        "        opt.apply_gradients([(grads, init_image)])\n",
        "        clipped = tf.clip_by_value(init_image, min_vals, max_vals)\n",
        "        init_image.assign(clipped)\n",
        "        end_time = time.time() \n",
        "    \n",
        "        if loss < best_loss:\n",
        "            # Update best loss and best image from total loss. \n",
        "            best_loss = loss\n",
        "            best_img = deprocess_img(init_image.numpy())\n",
        "\n",
        "        if i % display_interval== 0:\n",
        "            start_time = time.time()\n",
        "      \n",
        "            # Use the .numpy() method to get the concrete numpy array\n",
        "            plot_img = init_image.numpy()\n",
        "            plot_img = deprocess_img(plot_img)\n",
        "            imgs.append(plot_img)\n",
        "            IPython.display.clear_output(wait=True)\n",
        "            IPython.display.display_png(Image.fromarray(plot_img))\n",
        "            print('Iteration: {}'.format(i))        \n",
        "            print('Total loss: {:.4e},style loss: {:.4e},content loss: {:.4e},time: {:.4f}s'.format(loss, style_score, content_score, time.time() - start_time))\n",
        "            \n",
        "        history[i] = loss\n",
        "        \n",
        "    print('Total time: {:.4f}s'.format(time.time() - global_start))\n",
        "    IPython.display.clear_output(wait=True)\n",
        "    plt.figure(figsize=(14,4))\n",
        "    for i,img in enumerate(imgs):\n",
        "        plt.subplot(num_rows,num_cols,i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "      \n",
        "    return best_img, best_loss, history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjkcTsrgHC-k",
        "colab_type": "text"
      },
      "source": [
        "### 6.3 Teste do algoritmo\n",
        "\n",
        "Execute a célula abaixo para testar e visualizar o resultado do método de transferência de estilo usando 100 iterações. Isso deve demorar alguns minutos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiI_gv66HC-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_1, best_loss_1, history = run_style_transfer(content_path,style_path, num_iterations=100)\n",
        "print('Custo =', best_loss_1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCX7c3jjHC-n",
        "colab_type": "text"
      },
      "source": [
        "**Saída esperada:**\n",
        "\n",
        "Custo = tf.Tensor(262740.97, shape=(), dtype=float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-D6a1z0HC-o",
        "colab_type": "text"
      },
      "source": [
        "Execute a célula abaixo para visualizar o valor da função de custo total em função das épocas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV6Oo6oOHC-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cria vetor de épocas e faz o gráfico do custo em função das épocas\n",
        "\n",
        "tempo = range(1, len(history) + 1)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(tempo, history, 'bo')\n",
        "plt.title('Valor da função de custo')\n",
        "plt.xlabel('Iteração')\n",
        "plt.ylabel('Custo')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXgTa0G2HC-r",
        "colab_type": "text"
      },
      "source": [
        "### Visualização da imagem resultante\n",
        "\n",
        "Para visualizar corretamente a imagem resultante devemos remover o processamento inicial realizado na imagem de conteúdo usando a função `imshow` definida no arquivo nst_utils2.py. Para fazer isso, execute a célula abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcEEF-kBHC-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_results(best_img, content_path, style_path, show_large_final=True):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    content = load_img(content_path) \n",
        "    style = load_img(style_path)\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    imshow(content, 'Content Image')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    imshow(style, 'Style Image')\n",
        "\n",
        "    if show_large_final: \n",
        "        plt.figure(figsize=(10, 10))\n",
        "\n",
        "        plt.imshow(best_img)\n",
        "        plt.title('Output Image')\n",
        "        plt.show()    \n",
        "        \n",
        "show_results(best_1, content_path, style_path)          "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr2mTWwdHC-v",
        "colab_type": "text"
      },
      "source": [
        "## 7 - Testes com alterações dos parâmetros\n",
        "\n",
        "Como visto em aula, a função de custo total consiste de uma média ponderada entre as parcelas referentes ao conteúdo e ao estilo, conforme a seguinte equação:\n",
        "\n",
        "$$J(G) = \\alpha J_C(S,G) + \\beta J_S(S,G)$$\n",
        "\n",
        "Veremos o que acontece se alterarmos os valores dos pesos das parcelas da função de custo relativas ao conteúdo ($\\alpha$) e ao estilo ($\\beta$).\n",
        "\n",
        "\n",
        "### Exercício #7: Primeira alteração dos pesos das parcelas de conteúdo e estilo\n",
        "\n",
        "Diminua o peso do custo de estilo para 0.2e+03 e mantenha o peso do custo de conteúdo em 1e+03 e execute novamente a função `run_style_transfer`. Observe que no programa $\\alpha$ = `content_weight` e $\\beta$ = `style_weight`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7u2PmctHC-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARA VOCÊ FAZER: Teste de transferência de estilo com novos parâmetros\n",
        "\n",
        "# Altere as variáveis de ponderação das parcelas de conteúdo e de estilo da função de custo e\n",
        "# execute execute novamente a função run_style_transfer\n",
        "# alfa = content_weight\n",
        "# beta = style_weight\n",
        "\n",
        "### COMECE AQUI ### (≈ 1 linha)\n",
        "#best_2, best_loss_2, history2 = \n",
        "### TERMINE AQUI ###\n",
        "\n",
        "print('Custo =', best_loss_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpX3ugI0HC-y",
        "colab_type": "text"
      },
      "source": [
        "**Saída esperada:**\n",
        "\n",
        "Custo = tf.Tensor(98663.09, shape=(), dtype=float32)\n",
        "\n",
        "Execute a célula abaixo para visualizar a variação da função de custo durante o treinamento e a imagem resultante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvIxhXxfHC-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cria vetor de épocas e faz o gráfico da função de custo total em função das épocas\n",
        "\n",
        "tempo = range(1, len(history2) + 1)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(tempo, history2, 'bo')\n",
        "plt.title('Valor da função de custo')\n",
        "plt.xlabel('Iteração')\n",
        "plt.ylabel('Custo')\n",
        "plt.show()\n",
        "\n",
        "show_results(best_2, content_path, style_path)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbuhQRCfHC-1",
        "colab_type": "text"
      },
      "source": [
        "### Exercício #8: Segunda alteração dos pesos das parcelas de conteúdo e estilo\n",
        "\n",
        "Aumente o peso do custo de estilo para 5e+03 mantendo o peso do custo de conteúdo em 1e+03 e execute novamente a função run_style_transfer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QyUMRnIHC-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARA VOCÊ FAZER: Teste de transferência de estilo com novos parâmetros\n",
        "\n",
        "# Altere as variáveis de ponderação das parcelas de conteúdo e de estilo da função de custo e\n",
        "# execute execute novamente a função run_style_transfer\n",
        "### COMECE AQUI ### (≈ 1 linha)\n",
        "#best_3, best_loss_3, history3 = \n",
        "### TERMINE AQUI ###\n",
        "\n",
        "print('Custo =', best_loss_3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E77rkKHfHC-3",
        "colab_type": "text"
      },
      "source": [
        "**Saída esperada:**\n",
        "\n",
        "Custo = tf.Tensor(802923.1, shape=(), dtype=float32)\n",
        "\n",
        "Execute a célula abaixo para visualizar a variação da função de custo durante o treinamento e a imagem resultante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rVNTBG4HC-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cria vetor de épocas e faz o gráfico da função de custo total em função das épocas\n",
        "\n",
        "tempo = range(1, len(history3) + 1)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(tempo, history3, 'bo')\n",
        "plt.title('Valor da função de custo')\n",
        "plt.xlabel('Iteração')\n",
        "plt.ylabel('Custo')\n",
        "plt.show()\n",
        "\n",
        "show_results(best_3, content_path, style_path)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TbeAMy9HC-5",
        "colab_type": "text"
      },
      "source": [
        "### Exercício #9: Alteração das camadas usadas para descrever conteúdo e estilo\n",
        "\n",
        "Mantenha ambos os pesos do custo de estilo e de conteúdo iguais a 1e+03 e altere as camadas utilizadas para definir o conteúdo e o estilo das imagens. \n",
        "\n",
        "Para representar o conteúdo use as camadas `block5_conv3`.\n",
        "\n",
        "Para representar o estilo use as camdas `block1_conv2`, `block2_conv2`, `block3_conv2`, `block4_conv2` e `block5_conv2`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YfDWj38HC-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARA VOCÊ FAZER: Definir camadas de conteúdo e de estilo\n",
        "\n",
        "# Camada de conteúdo\n",
        "### COMECE AQUI ### (≈ 1 linha)\n",
        "#content_layers = \n",
        "### TERMINE AQUI ###\n",
        "\n",
        "# Camadas de estilo. Inclua uma lista com os nomes das camadas\n",
        "### COMECE AQUI ### (≈ 1 linha)\n",
        "#style_layers = \n",
        "### TERMINE AQUI ###\n",
        "\n",
        "num_content_layers = len(content_layers)\n",
        "num_style_layers = len(style_layers)\n",
        "\n",
        "print('Camadas de conteúdo:', content_layers)\n",
        "print('Camadas de estilo:', style_layers)\n",
        "\n",
        "# Execute a função de transferência de estilo \n",
        "### COMECE AQUI ### (≈ 1 linha)\n",
        "#best_4, best_loss_4, history4 = \n",
        "### TERMINE AQUI ###\n",
        "\n",
        "print('Custo =', best_loss_4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCzaZ9C7HC-7",
        "colab_type": "text"
      },
      "source": [
        "**Saída esperada:**\n",
        "\n",
        "Custo = tf.Tensor(94026.77, shape=(), dtype=float32)\n",
        "\n",
        "Execute a célula abaixo para visualizar a variação da função de custo durante o treinamento e a imagem resultante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smpjLZjWHC-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cria vetor de épocas e faz o gráfico da função de custo total em função das épocas\n",
        "\n",
        "tempo = range(1, len(history4) + 1)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(tempo, history4, 'bo')\n",
        "plt.title('Valor da função de custo')\n",
        "plt.xlabel('Iteração')\n",
        "plt.ylabel('Custo')\n",
        "plt.show()\n",
        "\n",
        "show_results(best_4, content_path, style_path)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZPwhHQNHC-9",
        "colab_type": "text"
      },
      "source": [
        "<font color='blue'>\n",
        "\n",
        "## Conclusões:\n",
        "\n",
        "1. Note que diminuir o peso da parcela do estilo na função de custo a imagem resultante vai parecer mais com a imagem de conteúdo, ou seja, menos estilo é transferida para a imagem gerada.\n",
        "\n",
        "2. Ao contrário, se aumentar o peso da parcela do estilo na função de custo a imagem resultante vai parecer mais com a imagem de estilo, ou seja, mais estilo é transferida para a imagem gerada.\n",
        "\n",
        "3. Conclui-se portanto que podemos controlar quanto de estilo transferimos para a nova imagem gerada simplesmente alterando os pesos das parcelas de conteúdo e de estilo da função de custo total.\n",
        "\n",
        "4. Outra forma de controlar a transferência de estilo é escolher as camadas que definem o conteúdo e o estilo das imagens. O uso de ativações de camadas iniciais força a imagem gerada ser muito similar à imagem de conteúdo (C) e o uso de ativações das camadas mais profundas força a imagem gerada ser mais similar à imagem de estilo.\n",
        "\n",
        "5. Outra forma de controlar o quanto de estilo é transferido para a imagem de conteúdo é usar um número de iterações menor ou maior. Essa técnica não foi testada nesse trabalho, mas você pode tentar fazer isso executando a função `run_style_transfer` com 1000 iterações. Após a entrega do trabalho faça isso e veja o resultado obtido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGan4hpeHC-9",
        "colab_type": "text"
      },
      "source": [
        "## 8 - Teste com outras imagens\n",
        "\n",
        "Tente transferir estilos para outras imagens. Os links a seguir possuem diversas imagens interssantes que podem ser usadas para transferência de estilo.\n",
        "\n",
        "https://towardsdatascience.com/style-transfer-styling-images-with-convolutional-neural-networks-7d215b58f461\n",
        "https://commons.wikimedia.org/wiki/File:Green_Sea_Turtle_grazing_seagrass.jpg\n",
        "https://commons.wikimedia.org/wiki/File:The_Great_Wave_off_Kanagawa.jpg\n",
        "https://commons.wikimedia.org/wiki/Commons:Featured_picture_candidates/Log/January_2005\n",
        "\n",
        "\n",
        "### Exercício #10: Teste de transferência de estilo para outra imagem\n",
        "\n",
        "Vamos testar o algoritmo de transferência de estilo com as imagens da cidade de São Francisco e Tytus. Essas imagens estão no diretório images com nomes sao_francisco.png e Tytus_Brzozowski.png."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "sJnoCmoFHC--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PARA VOCÊ FAZER: Realizar a transferência de estilo da imagem Tytus para a imagem da cidade de São Francisco.\n",
        "\n",
        "# Redefine as camadas de conteúdo e estilo originais\n",
        "content_layers = ['block5_conv2'] \n",
        "style_layers = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1','block5_conv1']\n",
        "\n",
        "### COMECE AQUI ### (≈ 1 linha)\n",
        "#nst_sao_franscisco, best_loss, history = \n",
        "### TERMINE AQUI ###\n",
        "\n",
        "print('Custo =', best_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiHckQCZHC-_",
        "colab_type": "text"
      },
      "source": [
        "**Saída esperada:**\n",
        "\n",
        "Custo = tf.Tensor(424244.5, shape=(), dtype=float32)\n",
        "\n",
        "Execute a célula abaixo para visualizar a imagem resultante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg17wLnAHC_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_results(nst_sao_franscisco, 'images/sao_francisco.png','images/Tytus_Brzozowski.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOUtmdLzHC_C",
        "colab_type": "text"
      },
      "source": [
        "### Teste para outra imagem interessante"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xoj3wi-HC_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nst_turtle, best_loss = run_style_transfer('images/Green_Sea_Turtle.jpg','images/Great_Wave_off_Kanagawa.jpg',num_iterations=100)\n",
        "show_results(nst_turtle, 'images/Green_Sea_Turtle.jpg','images/Great_Wave_off_Kanagawa.jpg')\n",
        "print('Custo =', best_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdzdnhGkHC_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}